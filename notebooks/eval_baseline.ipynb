{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c158a4d",
   "metadata": {},
   "source": [
    "# Baseline DTW Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac32571",
   "metadata": {},
   "source": [
    "## Load pair metadata and cached DTW distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paths\n",
    "pairs_path = Path('results/pairs_meta.parquet')\n",
    "dtw_cache_path = Path('results/dtw_cache.parquet')\n",
    "\n",
    "pairs = pd.read_parquet(pairs_path)\n",
    "dtw = pd.read_parquet(dtw_cache_path)\n",
    "\n",
    "# merge on pair index\n",
    "pairs = pairs.reset_index().rename(columns={'index':'pair_id'})\n",
    "merged = pairs.merge(dtw, on='pair_id')\n",
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde612f4",
   "metadata": {},
   "source": [
    "## ROC and DET curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute fpr, tpr for a range of thresholds using raw and normalised distances\n",
    "scores = {\n",
    "    'raw': merged['d_raw'],\n",
    "    'norm1': merged['d_norm1'],\n",
    "    'norm2': merged['d_norm2'],\n",
    "}\n",
    "labels = merged['label']\n",
    "\n",
    "roc_data = {}\n",
    "auc_scores = {}\n",
    "for key, vals in scores.items():\n",
    "    fpr, tpr, thr = metrics.roc_curve(labels, -vals)\n",
    "    roc_data[key] = (fpr, tpr, thr)\n",
    "    auc_scores[key] = metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "for key,(fpr,tpr,thr) in roc_data.items():\n",
    "    ax.plot(fpr,tpr,label=f'{key} (AUC={auc_scores[key]:.3f})')\n",
    "ax.plot([0,1],[0,1],'k--',lw=1)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig_path = Path('figures/roc_curve.png')\n",
    "fig_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "fig.savefig(fig_path)\n",
    "fig_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DET plot\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "for key,(fpr,tpr,thr) in roc_data.items():\n",
    "    fnr = 1 - tpr\n",
    "    ax.plot(metrics.det_curve(labels, -scores[key])[0], metrics.det_curve(labels,-scores[key])[1], label=key)\n",
    "ax.set_xlabel('False Positive Rate (log)')\n",
    "ax.set_ylabel('False Negative Rate (log)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig_path = Path('figures/det_curve.png')\n",
    "fig.savefig(fig_path)\n",
    "fig_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381fbdab",
   "metadata": {},
   "source": [
    "## Equal Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def compute_eer(fpr, tpr):\n",
    "    fnr = 1 - tpr\n",
    "    abs_diffs = np.abs(fpr - fnr)\n",
    "    idx = np.argmin(abs_diffs)\n",
    "    return fpr[idx]\n",
    "\n",
    "metrics_table = []\n",
    "for key,(fpr,tpr,thr) in roc_data.items():\n",
    "    eer = compute_eer(fpr, tpr)\n",
    "    metrics_table.append({'metric':key,'EER':eer,'AUC':auc_scores[key]})\n",
    "metrics_df = pd.DataFrame(metrics_table)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf4c96",
   "metadata": {},
   "source": [
    "## Threshold analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global threshold using d_norm1 by default\n",
    "thresholds = {}\n",
    "for key,(fpr,tpr,thr) in roc_data.items():\n",
    "    idx = np.argmin(np.abs(fpr - (1-tpr)))\n",
    "    thresholds[key] = thr[idx]\n",
    "thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c699c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Per-user thresholds based on d_norm1\n",
    "per_user = merged.groupby('userA')\n",
    "user_thresholds = {}\n",
    "for user, group in per_user:\n",
    "    fpr, tpr, thr = metrics.roc_curve(group['label'], -group['d_norm1'])\n",
    "    idx = np.argmin(np.abs(fpr - (1-tpr)))\n",
    "    user_thresholds[user] = thr[idx]\n",
    "plt.hist(list(user_thresholds.values()), bins=20)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Count')\n",
    "fig_path = Path('figures/threshold_dist.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_path)\n",
    "fig_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5aa8c",
   "metadata": {},
   "source": [
    "## Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88672926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_path = Path('results/baseline_metrics.csv')\n",
    "results_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "metrics_df.to_csv(results_path, index=False)\n",
    "results_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
